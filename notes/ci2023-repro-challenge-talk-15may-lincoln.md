# Reproducible Publications: The effectiveness of Open Science badges

## Talk with the Expert

### *This event is hosted by EDS book, Climate Informatics and Environmental Data Science Journal*

*Event facilitators:* Alejandro Coca-Castro and Anne Fouilloux

*Bring along your favourite hot/cold drink, snack and questions about the talk. And, while you wait for the event to start - please read more about the chairs, speaker and the event in this document. 🌻*

   * Date: 15 May 2023, Monday
   * Time: 09:00 - 09:30 UTC+1 (London time) (starting time in your time zone: [https://arewemeetingyet.com/London/2023-05-15/09:00](https://arewemeetingyet.com/London/2023-05-15/09:00) )
   * How you can join? Eventbrite page > [https://www.eventbrite.co.uk/e/talk-with-the-expert-the-effectiveness-of-open-science-badges-tickets-634523876997](https://www.eventbrite.co.uk/e/talk-with-the-expert-the-effectiveness-of-open-science-badges-tickets-634523876997) <--- Please register to receive a Zoom link
   * *All questions, comments, and recommendations are welcome on this Etherpad or on Zoom chat!*

Talk with the Expert features advances in open and reproducible research as part of the CIimate Informatics 2023 Reproducibility Challenge, [https://eds-book.github.io/reproducibility-challenge-2023](https://eds-book.github.io/reproducibility-challenge-2023).

*Thank you for joining us! We’re delighted to have you here.*

## 🗣️Welcome!

   * Please note that this call will be recorded
   * The video will be available on the EDS book YouTube channel in the next days: [https://www.youtube.com/channel/UC148zpdIEfRun-cUJbgbIyg](https://www.youtube.com/channel/UC148zpdIEfRun-cUJbgbIyg)
   * Turn on your webcam if you don’t mind sharing your face (or off if you do!)
   * Reminder: 
       * Code of conduct: [https://github.com/alan-turing-institute/environmental-ds-book/blob/master/CODE\_OF\_CONDUCT.md](https://github.com/alan-turing-institute/environmental-ds-book/blob/master/CODE\_OF\_CONDUCT.md) 
       * If you experience or witness unacceptable behaviour, or have any other concerns, please report it by contacting the project members (environmental.ds.book@gmail.com, acoca@turing.ac.uk).
       * To report an issue at this event involving one of the organisers, please email one of the members individually (acoca@turing.ac.uk, annef@simula.no)
       * We have enabled the closed caption (live transcription), please click on 'cc' at the bottom of your Zoom screen

## ⁉ Open Q \& A  

*The zoom room will remain open from 09:30-10:00 UTC+1 for an open Q\&A. This part of the call will not be recorded, and is optional for both speakers and the audience.*

   * Can you confirm that these 14 papers had received a "reproducibility badge" from the Journal editors?
       * Yes, they had, and this is the reason why there were selected
   * Were there reviewers guidelines for this journal referring to the badge?
       * Reviewers do not check the reproducibility (only superficial check like that there is data available), it is up to the editor to check further
   * Is there a formal training for journal to check that related to "open budget movement"?
       * No, this is a lot of work, even though journals make a lot of money
       * Teach people to do thing in a more reproducible way, but no budget yet, it is up to the authors of papers to advertise that their work has been reproduced in some way, otherwise they would stay behind
   * How much does it take to reproduce papers
       * if everything is available, it mays take about 4 days, but at the begining it takes much longer, this is very time consumming if for example everything is done in Excel spreadsheets
   * Bringing this back to Climate Science, what is the normal standard / understanding around badges or more broadly preparing data for FAIR sharing?
       * there are certain groups who are trying to do it, but in general individual researchers are not so involved and it is not their priority. Those in big labd/projects may have standard procedures, but in small labs researchers are mostly on their own
       * also the word "reproducibility" has different meanings in different contexts and scientific disciplines, and we are far from having a general agreement on what to do
   * Did the report provide guidance about how to do better?
       * yes, but they do what they want from it
   * a PhD position is being advertise on the topic at Sussex Psychology** - please provide a link so that we can advertise it**
       * there is also a role for RSE to help

## 📝 Notes, comments and references by attendees

   * Covering this paper: [https://journals.sagepub.com/doi/10.1177/09567976221140828](https://journals.sagepub.com/doi/10.1177/09567976221140828)
   * Slides for the talk: [https://talks.colling.net.nz/climate](https://talks.colling.net.nz/climate)
   * Data sharing increased exponentially over the last few years, and there was a need to organise that a bit
   * Requirements for an Open data badge: shareable data, a dictionary and an open license
   * Psychologicla Science submission guidelines are slightly different and includes "annotated copies of the code or syntax used for exploratory and principal analysis"
   * If badges worked it should be possible to "reproduce published results"
       * it started as a "secret project", with 13 reproducers attempting to reproduce results independently at first, and then as a group
       * all repos contained some data
       * 6/14 did not provide any code
           * the codes themselves had issues (hardcoded parameters, missing dependencies, missing degrees of freedom in the t-test, no information about the software used, etc.)
       * one paper provided code inside an Excel file, along with the raw data
       * reproducibility rating 1 paper out of 14 was exactly reproducible (although with the use of a container with old versions of R), 3 were rated as essentially reproducible, 6 partially reproducible, 1 mostly not, and 3 not at all
       * issues
           * lack of documentationand code
           * random seeds
           * copy \& paste errors
           * corrupted files
           * not providing raw data but heavily pre-processed data
           * no cleaning procedure specified
           * no version of packages
   * a lot of papers were not sharing code, althoug authorsguidelines asked for it
   * Most scientists want to do the right thing, but sometimes do not know how to do
   * At Sussex Psychology there is a person who tried to test reproducibility and spot gaps

## References shared

   * 

   * 

## Useful links

   * Climate Informatics 2023 Reproducibility Challenge, [https://eds-book.github.io/reproducibility-challenge-2023](https://eds-book.github.io/reproducibility-challenge-2023).
   * EDS book: [https://edsbook.org/](https://edsbook.org/) 
   * Climate Informatics: [http://www.climateinformatics.org/](http://www.climateinformatics.org/)
   * Environmental Data Science - part of Cambridge University Press and Assessment, [https://www.cambridge.org/core/journals/environmental-data-science](https://www.cambridge.org/core/journals/environmental-data-science)

## Feedback

What worked?

   * 

   * 

What didn’t work?

   * 

   * 

What would you change?

   * 

   * 

What surprised you?

   * 

   *

License: EDS book CC BY 4.0 adapted from Fireside chats template ([https://github.com/alan-turing-institute/the-turing-way/blob/cb557e2c0441b5f8669627c23e5686ec7faf96ff/book/website/community-handbook/templates/template-fireside-chat.md)](https://github.com/alan-turing-institute/the-turing-way/blob/cb557e2c0441b5f8669627c23e5686ec7faf96ff/book/website/community-handbook/templates/template-fireside-chat.md)) provided by The Turing Way provided under CC BY 4.0.

Timer: [https://cuckoo.team/ci2023-talk-expert](https://cuckoo.team/ci2023-talk-expert)